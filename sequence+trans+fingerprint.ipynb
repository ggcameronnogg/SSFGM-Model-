{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# 设置 Python 内置的随机数生成器的种子\n",
    "random.seed(42)\n",
    "# 设置 NumPy 的随机数生成器的种子\n",
    "np.random.seed(42)\n",
    "# 设置 PyTorch 随机数生成器的种子\n",
    "torch.manual_seed(42)\n",
    "# 如果使用 GPU, 设置 CUDA 随机数生成器的种子\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)  # 如果使用多个 GPU\n",
    "# 确保所有操作都是确定性的\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "def load_embeddings(npy_folder_path, max_length, embedding_type='proteinbert'):\n",
    "    features_dict = {}\n",
    "    for filename in os.listdir(npy_folder_path):\n",
    "        if filename.endswith('.npy'):\n",
    "            protein_id = filename[:-4]\n",
    "            feature = np.load(os.path.join(npy_folder_path, filename))\n",
    "            squeezed_feature = np.squeeze(feature)\n",
    "            if squeezed_feature.shape[0] > max_length:\n",
    "                padded_feature = squeezed_feature[:max_length, :]\n",
    "            else:\n",
    "                padding = np.zeros((max_length - squeezed_feature.shape[0], squeezed_feature.shape[1]))\n",
    "                padded_feature = np.vstack([squeezed_feature, padding])\n",
    "            features_dict[protein_id] = padded_feature\n",
    "    return features_dict\n",
    "\n",
    "def create_one_hot_features(fasta_file, max_length, amino_acids='ACDEFGHIKLMNPQRSTVWY'):\n",
    "    aa_to_onehot = {aa: np.eye(len(amino_acids))[i] for i, aa in enumerate(amino_acids)}\n",
    "    one_hot_features_dict = {}\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequence_id = record.id\n",
    "        encoded_seq = np.array([aa_to_onehot.get(aa, np.zeros(len(amino_acids))) for aa in str(record.seq)])\n",
    "        if len(encoded_seq) > max_length:\n",
    "            encoded_seq = encoded_seq[:max_length]  # 截断超长序列\n",
    "        padding_length = max_length - len(encoded_seq)\n",
    "        if padding_length > 0:  # 仅当需要填充时进行填充\n",
    "            padded_seq = np.pad(encoded_seq, ((0, padding_length), (0, 0)), 'constant')\n",
    "        else:\n",
    "            padded_seq = encoded_seq\n",
    "        one_hot_features_dict[sequence_id] = padded_seq\n",
    "    return one_hot_features_dict\n",
    "\n",
    "# 更新最大长度为100\n",
    "max_length = 183\n",
    "# 调用函数\n",
    "\n",
    "def combine_features(one_hot_features, proteinbert_features, esm_features):\n",
    "    combined_features_dict = {}\n",
    "    for seq_id in one_hot_features:\n",
    "        if seq_id in proteinbert_features and seq_id in esm_features:\n",
    "            combined_feature = np.concatenate([\n",
    "                proteinbert_features[seq_id], \n",
    "                esm_features[seq_id], \n",
    "                one_hot_features[seq_id]\n",
    "            ], axis=1)\n",
    "            combined_features_dict[seq_id] = combined_feature\n",
    "    return combined_features_dict\n",
    "\n",
    "fasta_file = 'amp_eval2.fasta'\n",
    "proteinbert_path = 'bert_amp_eval2'\n",
    "esm_path = 'esm_ebd_amp_eval2'\n",
    "one_hot_features = create_one_hot_features(fasta_file, max_length)\n",
    "proteinbert_features = load_embeddings(proteinbert_path, max_length, 'proteinbert')\n",
    "esm_features = load_embeddings(esm_path, max_length, 'esm')\n",
    "amp_eval_combined_features = combine_features(one_hot_features, proteinbert_features, esm_features)\n",
    "\n",
    "fasta_file = 'non_amp_eval2.fasta'\n",
    "proteinbert_path = 'bert_non_amp_eval2'\n",
    "esm_path = 'esm_ebd_non_amp_eval2'\n",
    "one_hot_features = create_one_hot_features(fasta_file, max_length)\n",
    "proteinbert_features = load_embeddings(proteinbert_path, max_length, 'proteinbert')\n",
    "esm_features = load_embeddings(esm_path, max_length, 'esm')\n",
    "decoy_amp_eval_combined_features = combine_features(one_hot_features, proteinbert_features, esm_features)\n",
    "\n",
    "fasta_file = 'amp_test2.fasta'\n",
    "proteinbert_path = 'bert_amp_test2'\n",
    "esm_path = 'esm_ebd_amp_test2'\n",
    "one_hot_features = create_one_hot_features(fasta_file, max_length)\n",
    "proteinbert_features = load_embeddings(proteinbert_path, max_length, 'proteinbert')\n",
    "esm_features = load_embeddings(esm_path, max_length, 'esm')\n",
    "amp_test_combined_features = combine_features(one_hot_features, proteinbert_features, esm_features)\n",
    "\n",
    "fasta_file = 'non_amp_test2.fasta'\n",
    "proteinbert_path = 'bert_non_amp_test2'\n",
    "esm_path = 'esm_ebd_non_amp_test2'\n",
    "one_hot_features = create_one_hot_features(fasta_file, max_length)\n",
    "proteinbert_features = load_embeddings(proteinbert_path, max_length, 'proteinbert')\n",
    "esm_features = load_embeddings(esm_path, max_length, 'esm')\n",
    "decoy_amp_test_combined_features = combine_features(one_hot_features, proteinbert_features, esm_features)\n",
    "\n",
    "fasta_file = 'amp_train2.fasta'\n",
    "proteinbert_path = 'bert_amp_train2'\n",
    "esm_path = 'esm_ebd_amp_train2'\n",
    "one_hot_features = create_one_hot_features(fasta_file, max_length)\n",
    "proteinbert_features = load_embeddings(proteinbert_path, max_length, 'proteinbert')\n",
    "esm_features = load_embeddings(esm_path, max_length, 'esm')\n",
    "amp_train_combined_features = combine_features(one_hot_features, proteinbert_features, esm_features)\n",
    "\n",
    "fasta_file = 'non_amp_train2.fasta'\n",
    "proteinbert_path = 'bert_non_amp_train2'\n",
    "esm_path = 'esm_ebd_non_amp_train2'\n",
    "one_hot_features = create_one_hot_features(fasta_file, max_length)\n",
    "proteinbert_features = load_embeddings(proteinbert_path, max_length, 'proteinbert')\n",
    "esm_features = load_embeddings(esm_path, max_length, 'esm')\n",
    "decoy_amp_train_combined_features = combine_features(one_hot_features, proteinbert_features, esm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_residue_positions(pdb_file, max_residues=183):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('PDB', pdb_file)\n",
    "    model = structure[0]  # Typically, only the first model is used\n",
    "\n",
    "    residue_positions = []\n",
    "    for chain in model:\n",
    "        for residue in chain:\n",
    "            if residue.id[0] == ' ' and 'CA' in residue:  # Filter out non-standard residues and ensure CA exists\n",
    "                residue_positions.append(residue['CA'].coord)\n",
    "                if len(residue_positions) >= max_residues:  # If reached max_residues, stop adding more residues\n",
    "                    break\n",
    "        if len(residue_positions) >= max_residues:\n",
    "            break\n",
    "    return residue_positions\n",
    "\n",
    "def build_edges_with_attr(residue_positions, cutoff):\n",
    "    edges = []\n",
    "    edge_attrs = []\n",
    "    num_residues = len(residue_positions)  # Get the number of residues (nodes)\n",
    "    for i in range(num_residues):\n",
    "        for j in range(i + 1, num_residues):\n",
    "            dist = np.linalg.norm(residue_positions[i] - residue_positions[j])\n",
    "            if dist < cutoff:\n",
    "                edges.append([i, j])\n",
    "                edges.append([j, i])\n",
    "                edge_attrs.append([dist])\n",
    "                edge_attrs.append([dist])\n",
    "    # Convert to tensors and add boundary check\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "    \n",
    "    # Boundary check\n",
    "    if edge_index.max().item() >= num_residues:\n",
    "        raise ValueError(f\"Edge index out of bounds! Max index: {edge_index.max().item()}, Num residues: {num_residues}\")\n",
    "    \n",
    "    return edge_index, edge_attr\n",
    "\n",
    "def create_graph(feature_array, pdb_file, cutoff=10.0, is_amp=True, max_residues=183):\n",
    "    residue_positions = get_residue_positions(pdb_file, max_residues)\n",
    "    edge_index, edge_attr = build_edges_with_attr(residue_positions, cutoff)\n",
    "    x = torch.tensor(feature_array, dtype=torch.float)\n",
    "    y = torch.tensor([1 if is_amp else 0], dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "def create_graphs_for_sequences(features_dict, pdb_folder, is_amp=True, max_residues=183):\n",
    "    graphs = {}\n",
    "    for seq_id, features in features_dict.items():\n",
    "        pdb_file = os.path.join(pdb_folder, f\"{seq_id}.pdb\")\n",
    "        if os.path.exists(pdb_file):\n",
    "            try:\n",
    "                graph = create_graph(features, pdb_file, is_amp=is_amp, max_residues=max_residues)\n",
    "                graphs[seq_id] = graph\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {seq_id} from {pdb_file}: {e}\")\n",
    "        else:\n",
    "            logging.warning(f\"No PDB file found for {seq_id}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "amp_graphs = create_graphs_for_sequences(amp_eval_combined_features, 'pdb_amp_eval2', is_amp=True)\n",
    "decoy_graphs = create_graphs_for_sequences(decoy_amp_eval_combined_features, 'pdb_non_amp_eval2', is_amp=False)\n",
    "\n",
    "#for test files\n",
    "amp_test_graphs = create_graphs_for_sequences(amp_test_combined_features, 'pdb_amp_test2', is_amp=True)\n",
    "decoy_test_graphs = create_graphs_for_sequences(decoy_amp_test_combined_features, 'pdb_non_amp_test2', is_amp=False)\n",
    "\n",
    "\n",
    "amp_train_graphs = create_graphs_for_sequences(amp_train_combined_features, 'pdb_amp_train2', is_amp=True)\n",
    "decoy_train_graphs = create_graphs_for_sequences(decoy_amp_train_combined_features, 'pdb_non_amp_train2', is_amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class PeptideDataset(Dataset):\n",
    "    def __init__(self, root_dir, fasta_file, max_vertices=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.peptides = self.parse_fasta(fasta_file)\n",
    "        self.max_vertices = max_vertices if max_vertices is not None else self.determine_max_vertices()\n",
    "\n",
    "    def parse_fasta(self, fasta_file):\n",
    "        peptides = []\n",
    "        with open(fasta_file, 'r') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('>'):\n",
    "                    peptide_id = line.strip().split()[0][1:]\n",
    "                    peptides.append(peptide_id)\n",
    "        return peptides\n",
    "\n",
    "    def determine_max_vertices(self):\n",
    "        max_vertices = 0\n",
    "        for peptide_id in self.peptides:\n",
    "            path = os.path.join(self.root_dir, peptide_id, 'p1_input_feat.npy')\n",
    "            if os.path.exists(path):\n",
    "                current_vertices = np.load(path).shape[0]\n",
    "                max_vertices = max(max_vertices, current_vertices)\n",
    "        return max_vertices\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.peptides)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        peptide_id = self.peptides[idx]\n",
    "        try:\n",
    "            features = {\n",
    "                'input_feat': np.load(os.path.join(self.root_dir, peptide_id, 'p1_input_feat.npy')),\n",
    "                'rho_coords': np.load(os.path.join(self.root_dir, peptide_id, 'p1_rho_wrt_center.npy')),\n",
    "                'theta_coords': np.load(os.path.join(self.root_dir, peptide_id, 'p1_theta_wrt_center.npy')),\n",
    "                'mask': np.load(os.path.join(self.root_dir, peptide_id, 'p1_mask.npy'))\n",
    "            }\n",
    "\n",
    "            max_vertices = 5109  # 设置最大顶点数为5109\n",
    "\n",
    "            # 调整所有特征到max_vertices\n",
    "            for key in features:\n",
    "                current_length = features[key].shape[0]\n",
    "                if current_length < max_vertices:\n",
    "                    padding_shape = (max_vertices - current_length,) + features[key].shape[1:]\n",
    "                    padding = np.zeros(padding_shape, dtype=features[key].dtype)\n",
    "                    features[key] = np.concatenate((features[key], padding), axis=0)\n",
    "                elif current_length > max_vertices:\n",
    "                    features[key] = features[key][:max_vertices]\n",
    "                \n",
    "                features[key] = np.nan_to_num(features[key])\n",
    "\n",
    "            label = 0 # 所有样本的标签都是\n",
    "            features_tensor = {key: torch.tensor(val, dtype=torch.float32) for key, val in features.items()}\n",
    "            return features_tensor, torch.tensor(label, dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {peptide_id}: {e}\")\n",
    "            return None   # 遇到错误时返回None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'finger_amp_eval2'\n",
    "fasta_file = 'amp_eval2.fasta'\n",
    "model2_eval_amp_dataset = PeptideDataset(root_dir=root_dir, fasta_file=fasta_file)\n",
    "\n",
    "root_dir = 'finger_amp_train2'\n",
    "fasta_file = 'amp_train2.fasta'\n",
    "model2_trian_amp_dataset = PeptideDataset(root_dir=root_dir, fasta_file=fasta_file)\n",
    "\n",
    "root_dir = 'finger_amp_test2'\n",
    "fasta_file = 'amp_test2.fasta'\n",
    "model2_test_amp_dataset = PeptideDataset(root_dir=root_dir, fasta_file=fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'finger_non_amp_eval2'\n",
    "fasta_file = 'non_amp_eval2.fasta'\n",
    "model2_decoy_eval_amp_dataset = PeptideDataset(root_dir=root_dir, fasta_file=fasta_file)\n",
    "\n",
    "root_dir = 'finger_non_amp_test2'\n",
    "fasta_file = 'non_amp_test2.fasta'\n",
    "model2_decoy_test_amp_dataset = PeptideDataset(root_dir=root_dir, fasta_file=fasta_file)\n",
    "\n",
    "root_dir = 'finger_non_amp_train2'\n",
    "fasta_file = 'non_amp_train2.fasta'\n",
    "model2_decoy_trian_amp_dataset = PeptideDataset(root_dir=root_dir, fasta_file=fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_train = list(amp_train_graphs.values()) + list(decoy_train_graphs.values())\n",
    "GCN_eval = list(amp_graphs.values()) + list(decoy_graphs.values())\n",
    "GCN_test = list(amp_test_graphs.values())+list(decoy_test_graphs.values())\n",
    "fingerprint_trian = model2_trian_amp_dataset + model2_decoy_trian_amp_dataset\n",
    "fingerprint_eval = model2_eval_amp_dataset + model2_decoy_eval_amp_dataset\n",
    "fingerprint_test = model2_test_amp_dataset + model2_decoy_test_amp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, graph_dataset, feature_dataset):\n",
    "        assert len(graph_dataset) == len(feature_dataset), \"Datasets must be of the same size\"\n",
    "        self.graph_dataset = graph_dataset\n",
    "        self.feature_dataset = feature_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph_data = self.graph_dataset[idx]\n",
    "        feature_data, label = self.feature_dataset[idx]\n",
    "        return graph_data, feature_data, label\n",
    "    \n",
    "train_combined_dataset = CombinedDataset(GCN_train, fingerprint_trian)\n",
    "test_combined_dataset = CombinedDataset(GCN_test, fingerprint_test)\n",
    "eval_combined_dataset = CombinedDataset(GCN_eval, fingerprint_eval)\n",
    "\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    data_gcn_list = [item[0] for item in batch]  # 提取每个元组的第一部分\n",
    "    data_masif_list = [item[1] for item in batch]  # 提取每个元组的第二部分\n",
    "\n",
    "    # 对GCN数据进行批处理\n",
    "    data_gcn_batch = Batch.from_data_list(data_gcn_list)\n",
    "\n",
    "    # 对MaSIF数据进行批处理，假设MaSIF数据是一个字典\n",
    "    masif_keys = data_masif_list[0].keys()\n",
    "    data_masif_batch = {key: torch.stack([d[key] for d in data_masif_list]) for key in masif_keys}\n",
    "    \n",
    "    return data_gcn_batch, data_masif_batch\n",
    "\n",
    "\n",
    "#final_train_dataset = train_combined_dataset + eval_combined_dataset\n",
    "train_combined_loader = DataLoader(train_combined_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_combined_loader = DataLoader(test_combined_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "eval_combined_loader = DataLoader(eval_combined_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Dropout, LayerNorm\n",
    "from torch_geometric.nn import GCNConv, GATConv, TransformerConv, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# 定义ImprovedGCN模型\n",
    "class ImprovedGCNWithTransformer(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, heads=4, dropout_rate=0.5, transformer_out_channels=64):\n",
    "        super(ImprovedGCNWithTransformer, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 1024)\n",
    "        self.conv2 = GCNConv(1024, 512)\n",
    "        self.conv3 = GCNConv(512, 256)\n",
    "        self.linear_transform = Linear(256, transformer_out_channels)  # 调整维度以匹配Transformer的输入\n",
    "\n",
    "        # Transformer layer\n",
    "        self.transformer = TransformerConv(transformer_out_channels, transformer_out_channels, heads=heads, dropout=dropout_rate, concat=True)\n",
    "        self.layer_norm = LayerNorm(transformer_out_channels * heads)  # 层归一化\n",
    "\n",
    "        self.attn1 = GATConv(transformer_out_channels * heads, 16 // heads, heads=heads, concat=True)\n",
    "        self.fc = Linear(16, num_classes)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, data, return_features = False ):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear_transform(x)  # 调整维度\n",
    "        x = self.transformer(x, edge_index)  # 应用Transformer层\n",
    "        x = self.layer_norm(x)  # 应用层归一化\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.attn1(x, edge_index)  # 应用注意力层\n",
    "        x = global_mean_pool(x, data.batch)  # 全局平均池化\n",
    "        if return_features:\n",
    "            return x\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 定义MaSIF_site_PyTorch模型\n",
    "class MaSIF_site_PyTorch(nn.Module):\n",
    "    def __init__(self, n_thetas, n_rhos, n_feat, n_rotations, dropout_rate=0.5):\n",
    "        super(MaSIF_site_PyTorch, self).__init__()\n",
    "        self.n_thetas = n_thetas\n",
    "        self.n_rhos = n_rhos\n",
    "        self.n_feat = n_feat\n",
    "        self.n_rotations = n_rotations\n",
    "\n",
    "        # Parameters\n",
    "        self.mu_rho = nn.Parameter(torch.Tensor(self.n_rotations, 1))\n",
    "        self.sigma_rho = nn.Parameter(torch.Tensor(self.n_rotations, 1))\n",
    "        self.mu_theta = nn.Parameter(torch.Tensor(self.n_rotations, 1))\n",
    "        self.sigma_theta = nn.Parameter(torch.Tensor(self.n_rotations, 1))\n",
    "\n",
    "        # Initialize parameters\n",
    "        nn.init.uniform_(self.mu_rho, 0, 1)\n",
    "        nn.init.constant_(self.sigma_rho, 0.5)\n",
    "        nn.init.uniform_(self.mu_theta, 0, 2 * np.pi)\n",
    "        nn.init.constant_(self.sigma_theta, 0.5)\n",
    "\n",
    "        # Layers\n",
    "        self.avgpool1d = nn.AvgPool1d(kernel_size=6, stride=5)  # Adjust these values based on desired output size\n",
    "        self.fc1 = nn.Linear(40840, 2)\n",
    "\n",
    "    def forward(self, input_feat, rho_coords, theta_coords, mask, return_features = False):\n",
    "        batch_size, n_vertices, num_points, n_feat = input_feat.size()\n",
    "        input_feat = input_feat.mean(dim=2)\n",
    "\n",
    "        output_feats = []\n",
    "        for k in range(self.n_rotations):\n",
    "            rotated_theta_coords = theta_coords + k * 2 * np.pi / self.n_rotations\n",
    "            rotated_theta_coords %= 2 * np.pi\n",
    "\n",
    "            rho_gauss = torch.exp(-torch.square(rho_coords - self.mu_rho[k]) / (2 * torch.square(self.sigma_rho[k]) + 1e-5))\n",
    "            theta_gauss = torch.exp(-torch.square(rotated_theta_coords - self.mu_theta[k]) / (2 * torch.square(self.sigma_theta[k]) + 1e-5))\n",
    "\n",
    "            gauss_activations = rho_gauss * theta_gauss * mask\n",
    "            gauss_activations /= torch.sum(gauss_activations, dim=1, keepdim=True) + 1e-5\n",
    "\n",
    "            gauss_activations = gauss_activations.unsqueeze(3)\n",
    "            gauss_activations = gauss_activations.expand(-1, -1, -1, n_feat)\n",
    "\n",
    "            gauss_desc = torch.sum(gauss_activations * input_feat.unsqueeze(2), dim=2)\n",
    "            output_feats.append(gauss_desc)\n",
    "        \n",
    "        output_feats = torch.cat(output_feats, dim=2)\n",
    "        #print(output_feats.shape)\n",
    "        output_feats = output_feats.permute(0, 2, 1)  # [batch_size, 40, 5109]\n",
    "        #print(output_feats.shape)\n",
    "        # Apply AvgPool1d to reduce the middle dimension from 5109 to 1000\n",
    "        output_feats = self.avgpool1d(output_feats)  # [batch_size, 40, 1000]\n",
    "        #print(output_feats.shape)\n",
    "        output_feats = output_feats.permute(0, 2, 1)  # [batch_size, 1000, 40]\n",
    "        #print(output_feats.shape)\n",
    "        output_feats = output_feats.reshape(batch_size, -1)  # Flatten to feed into the linear layer\n",
    "        \n",
    "        if return_features:\n",
    "            return output_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, model_gcn, model_masif, output_features, num_classes):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.model_gcn = model_gcn\n",
    "        self.model_masif = model_masif\n",
    "        self.fusion_layer = nn.Linear(output_features, 2)\n",
    "\n",
    "    def forward(self, data_gcn, data_masif):\n",
    "        # 提取各自模型的特征\n",
    "        gcn_features = self.model_gcn(data_gcn, return_features=True)\n",
    "        input_feat = data_masif['input_feat']\n",
    "        rho_coords = data_masif['rho_coords']\n",
    "        theta_coords = data_masif['theta_coords']\n",
    "        mask = data_masif['mask']\n",
    "        masif_features = self.model_masif(input_feat, rho_coords, theta_coords, mask, return_features=True)\n",
    "        #print(\"GCN Features Shape:\", gcn_features.shape)\n",
    "        #print(\"MaSIF Features Shape:\", masif_features.shape)\n",
    "\n",
    "        # 特征融合\n",
    "        combined_features = torch.cat((gcn_features, masif_features), dim=1)\n",
    "        combined_features = F.relu(combined_features)\n",
    "        \n",
    "        # 分类层\n",
    "        output = self.fusion_layer(combined_features)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 实例化单独的模型\n",
    "model_gcn = ImprovedGCNWithTransformer(num_features=3604, num_classes=2).to(device)\n",
    "model_masif = MaSIF_site_PyTorch(n_thetas=16, n_rhos=5, n_feat=5, n_rotations=8).to(device)\n",
    "\n",
    "# 假设从GCN和MaSIF模型中提取的特征数量，需要根据具体情况来设置\n",
    "gcn_output_features = 32  # 假设GCN模型最后一个GAT层输出32维特征\n",
    "masif_output_features = 5 * 8  # MaSIF模型输出8次旋转的5维特征\n",
    "\n",
    "# 实例化融合模型\n",
    "fusion_model = FusionModel(model_gcn, model_masif, 40856, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6906, Train Accuracy: 62.38%\n",
      "Epoch 1/10: Test Loss: 0.6854, Accuracy: 70.32%, AUC: 0.6967, SENS: 0.7394, SPEC: 0.6540, MCC: 0.3929\n",
      "Saved new best model with accuracy: 70.32%\n",
      "Epoch 2/10, Train Loss: 0.6800, Train Accuracy: 71.77%\n",
      "Epoch 2/10: Test Loss: 0.6708, Accuracy: 75.61%, AUC: 0.7543, SENS: 0.7662, SPEC: 0.7424, MCC: 0.5052\n",
      "Saved new best model with accuracy: 75.61%\n",
      "Epoch 3/10, Train Loss: 0.6642, Train Accuracy: 76.92%\n",
      "Epoch 3/10: Test Loss: 0.6542, Accuracy: 78.77%, AUC: 0.7941, SENS: 0.7528, SPEC: 0.8354, MCC: 0.5812\n",
      "Saved new best model with accuracy: 78.77%\n",
      "Epoch 4/10, Train Loss: 0.6463, Train Accuracy: 79.80%\n",
      "Epoch 4/10: Test Loss: 0.6345, Accuracy: 82.06%, AUC: 0.8232, SENS: 0.8065, SPEC: 0.8399, MCC: 0.6401\n",
      "Saved new best model with accuracy: 82.06%\n",
      "Epoch 5/10, Train Loss: 0.6285, Train Accuracy: 81.99%\n",
      "Epoch 5/10: Test Loss: 0.6157, Accuracy: 82.58%, AUC: 0.8192, SENS: 0.8624, SPEC: 0.7759, MCC: 0.6418\n",
      "Saved new best model with accuracy: 82.58%\n",
      "Epoch 6/10, Train Loss: 0.6137, Train Accuracy: 81.19%\n",
      "Epoch 6/10: Test Loss: 0.6030, Accuracy: 83.16%, AUC: 0.8295, SENS: 0.8434, SPEC: 0.8155, MCC: 0.6566\n",
      "Saved new best model with accuracy: 83.16%\n",
      "Epoch 7/10, Train Loss: 0.6025, Train Accuracy: 81.76%\n",
      "Epoch 7/10: Test Loss: 0.5938, Accuracy: 83.16%, AUC: 0.8264, SENS: 0.8602, SPEC: 0.7927, MCC: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.5962, Train Accuracy: 81.50%\n",
      "Epoch 8/10: Test Loss: 0.5887, Accuracy: 83.16%, AUC: 0.8266, SENS: 0.8591, SPEC: 0.7942, MCC: 0.6545\n",
      "Epoch 9/10, Train Loss: 0.5924, Train Accuracy: 81.74%\n",
      "Epoch 9/10: Test Loss: 0.5858, Accuracy: 83.03%, AUC: 0.8241, SENS: 0.8647, SPEC: 0.7835, MCC: 0.6512\n",
      "Epoch 10/10, Train Loss: 0.5911, Train Accuracy: 81.78%\n",
      "Epoch 10/10: Test Loss: 0.5855, Accuracy: 82.97%, AUC: 0.8233, SENS: 0.8647, SPEC: 0.7820, MCC: 0.6498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = AdamW(fusion_model.parameters(), lr=0.00001, weight_decay=6e-1)\n",
    "scheduler_cosine = CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "best_accuracy = 0.0  # 初始化最高准确性\n",
    "best_model1_path = '12_9_ben1transfinger_model1.pth'  # 定义最好模型的保存路径\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for data_gcn, data_masif in data_loader:\n",
    "            # 数据处理\n",
    "            data_gcn.to(device)\n",
    "            input_feat = data_masif['input_feat'].to(device)\n",
    "            rho_coords = data_masif['rho_coords'].to(device)\n",
    "            theta_coords = data_masif['theta_coords'].to(device)\n",
    "            mask = data_masif['mask'].to(device)\n",
    "            labels = data_gcn.y.to(device)\n",
    "            \n",
    "            # 正向传播\n",
    "            outputs = model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # 计算总体指标\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        auc_score = roc_auc_score(all_labels, all_preds)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy, auc_score, sensitivity, specificity, mcc\n",
    "epochs = 10\n",
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    fusion_model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for data_gcn, data_masif in train_combined_loader:\n",
    "        # 处理数据\n",
    "        data_gcn.to(device)\n",
    "        input_feat = data_masif['input_feat'].to(device)\n",
    "        rho_coords = data_masif['rho_coords'].to(device)\n",
    "        theta_coords = data_masif['theta_coords'].to(device)\n",
    "        mask = data_masif['mask'].to(device)\n",
    "        labels = data_gcn.y.to(device)\n",
    "\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = fusion_model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算准确性\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # 输出训练性能\n",
    "    avg_loss = total_loss / len(train_combined_loader)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    test_loss, test_accuracy, test_auc, test_sens, test_spec, test_mcc = evaluate_model(fusion_model, test_combined_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{epochs}: Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, AUC: {test_auc:.4f}, SENS: {test_sens:.4f}, SPEC: {test_spec:.4f}, MCC: {test_mcc:.4f}')\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy  # 更新最高准确性\n",
    "        torch.save(fusion_model.state_dict(), best_model1_path)  # 保存模型\n",
    "        print(f'Saved new best model with accuracy: {best_accuracy:.2f}%')\n",
    "    scheduler_cosine.step()\n",
    "    scheduler_plateau.step(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 12_9_ben1transfinger_model1.pth\n",
      "Test Loss: 0.6025, Accuracy: 83.16%, AUC: 0.8943, SENS: 0.8434, SPEC: 0.8155, MCC: 0.6566\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# 定义一个加载模型的函数\n",
    "def load_model(model, path='12_9_ben1transfinger_model1.pth'):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f'Model loaded from {path}')\n",
    "    return model\n",
    "\n",
    "# 定义一个绘制 ROC 曲线的函数\n",
    "def plot_roc_curve(labels, scores, title=\"ROC Curve\"):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # 绘制对角线\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# 使用最佳模型在测试集上进行测试并打印所有指标\n",
    "def test_model_and_print_metrics(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_scores = []  # 用于保存正类的概率\n",
    "    all_preds = []   # 保存预测值\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_gcn, data_masif in test_loader:\n",
    "            # 数据处理\n",
    "            data_gcn.to(device)\n",
    "            input_feat = data_masif['input_feat'].to(device)\n",
    "            rho_coords = data_masif['rho_coords'].to(device)\n",
    "            theta_coords = data_masif['theta_coords'].to(device)\n",
    "            mask = data_masif['mask'].to(device)\n",
    "            labels = data_gcn.y.to(device)\n",
    "\n",
    "            # 正向传播\n",
    "            outputs = model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 获取预测概率和预测值\n",
    "            scores = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # 获取正类的预测概率\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()  # 获取预测值\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_scores.extend(scores)  # 保存正类的预测概率\n",
    "            all_preds.extend(preds)    # 保存预测值\n",
    "            total_correct += (preds == labels).sum()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "    # 计算测试集损失\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # 计算 Accuracy\n",
    "    accuracy = total_correct / total_samples * 100\n",
    "\n",
    "    # 计算 AUC\n",
    "    auc_score = roc_auc_score(all_labels, all_scores)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # 计算 Sensitivity 和 Specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # 计算 MCC\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    # 获取当前学习率\n",
    "    #current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # 打印所有指标\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, AUC: {auc_score:.4f}, '\n",
    "          f'SENS: {sensitivity:.4f}, SPEC: {specificity:.4f}, MCC: {mcc:.4f}')\n",
    "    #print(f'Current learning rate: {current_lr:.8f}')\n",
    "    \n",
    "    # 绘制 ROC 曲线\n",
    "    plot_roc_curve(all_labels, all_scores, title=\"ROC Curve on Test Set\")\n",
    "best_model2_path = '12_9_ben1transfinger_model1.pth' \n",
    "# 加载模型并进行测试\n",
    "fusion_model = FusionModel(model_gcn, model_masif, 40856, num_classes=2).to(device)\n",
    "fusion_model.to(device)\n",
    "# 加载之前保存的最佳模型\n",
    "fusion_model = load_model(fusion_model, best_model2_path)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 使用最佳模型在测试集上进行推理并绘制 ROC 曲线\n",
    "test_model_and_print_metrics(fusion_model, test_combined_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "# 融合模型类\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, model_gcn, model_masif, output_features, num_classes):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.model_gcn = model_gcn\n",
    "        self.model_masif = model_masif\n",
    "        self.expand_gcn = nn.Linear(16, 256)  # 例如256\n",
    "        # MaSIF的输出降维到同样的维度\n",
    "        self.reduce_masif = nn.Linear(40840, 256)  # 例如256\n",
    "        # 融合后的特征进一步连接到分类器\n",
    "        self.fusion_layer = nn.Linear(2 * 256, num_classes)\n",
    "        \n",
    "    def forward(self, data_gcn, data_masif):\n",
    "        # 提取各自模型的特征\n",
    "        gcn_features = self.model_gcn(data_gcn, return_features=True)\n",
    "        input_feat = data_masif['input_feat']\n",
    "        rho_coords = data_masif['rho_coords']\n",
    "        theta_coords = data_masif['theta_coords']\n",
    "        mask = data_masif['mask']\n",
    "        masif_features = self.model_masif(input_feat, rho_coords, theta_coords, mask, return_features=True)\n",
    "        #print(\"GCN Features Shape:\", gcn_features.shape)\n",
    "        #print(\"MaSIF Features Shape:\", masif_features.shape)\n",
    "        \n",
    "        gcn_features = F.relu(self.expand_gcn(gcn_features))\n",
    "        masif_features = F.relu(self.reduce_masif(masif_features))\n",
    "        # 特征融合\n",
    "        combined_features = torch.cat((gcn_features, masif_features), dim=1)\n",
    "        #combined_features = F.relu(combined_features)\n",
    "        \n",
    "        # 分类层\n",
    "        output = self.fusion_layer(combined_features)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 实例化单独的模型\n",
    "model_gcn = ImprovedGCNWithTransformer(num_features=3604, num_classes=2).to(device)\n",
    "model_masif = MaSIF_site_PyTorch(n_thetas=16, n_rhos=5, n_feat=5, n_rotations=8).to(device)\n",
    "\n",
    "# 假设从GCN和MaSIF模型中提取的特征数量，需要根据具体情况来设置\n",
    "gcn_output_features = 32  # 假设GCN模型最后一个GAT层输出32维特征\n",
    "masif_output_features = 5 * 8  # MaSIF模型输出8次旋转的5维特征\n",
    "total_output_features = 40840\n",
    "\n",
    "# 实例化融合模型\n",
    "fusion_model = FusionModel(model_gcn, model_masif, 40840, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.6221, Train Accuracy: 66.93%\n",
      "Epoch 1/20: Test Loss: 0.5170, Accuracy: 78.71%, AUC: 0.7945, SENS: 0.7461, SPEC: 0.8430, MCC: 0.5821\n",
      "Current learning rate: 0.000020\n",
      "Saved new best model with accuracy: 78.71% and learning rate: 0.000020\n",
      "Epoch 2/20, Train Loss: 0.4683, Train Accuracy: 81.68%\n",
      "Epoch 2/20: Test Loss: 0.4057, Accuracy: 84.19%, AUC: 0.8409, SENS: 0.8479, SPEC: 0.8338, MCC: 0.6784\n",
      "Current learning rate: 0.000018\n",
      "Saved new best model with accuracy: 84.19% and learning rate: 0.000018\n",
      "Epoch 3/20, Train Loss: 0.3950, Train Accuracy: 85.98%\n",
      "Epoch 3/20: Test Loss: 0.3729, Accuracy: 86.06%, AUC: 0.8630, SENS: 0.8479, SPEC: 0.8780, MCC: 0.7197\n",
      "Current learning rate: 0.000016\n",
      "Saved new best model with accuracy: 86.06% and learning rate: 0.000016\n",
      "Epoch 4/20, Train Loss: 0.3596, Train Accuracy: 86.87%\n",
      "Epoch 4/20: Test Loss: 0.3579, Accuracy: 86.65%, AUC: 0.8723, SENS: 0.8345, SPEC: 0.9101, MCC: 0.7362\n",
      "Current learning rate: 0.000013\n",
      "Saved new best model with accuracy: 86.65% and learning rate: 0.000013\n",
      "Epoch 5/20, Train Loss: 0.3314, Train Accuracy: 88.11%\n",
      "Epoch 5/20: Test Loss: 0.3485, Accuracy: 86.71%, AUC: 0.8724, SENS: 0.8378, SPEC: 0.9070, MCC: 0.7367\n",
      "Current learning rate: 0.000010\n",
      "Saved new best model with accuracy: 86.71% and learning rate: 0.000010\n",
      "Epoch 6/20, Train Loss: 0.3150, Train Accuracy: 88.66%\n",
      "Epoch 6/20: Test Loss: 0.3391, Accuracy: 86.77%, AUC: 0.8691, SENS: 0.8602, SPEC: 0.8780, MCC: 0.7328\n",
      "Current learning rate: 0.000007\n",
      "Saved new best model with accuracy: 86.77% and learning rate: 0.000007\n",
      "Epoch 7/20, Train Loss: 0.2996, Train Accuracy: 89.06%\n",
      "Epoch 7/20: Test Loss: 0.3408, Accuracy: 86.58%, AUC: 0.8638, SENS: 0.8770, SPEC: 0.8506, MCC: 0.7259\n",
      "Current learning rate: 0.000004\n",
      "Epoch 8/20, Train Loss: 0.2911, Train Accuracy: 89.63%\n",
      "Epoch 8/20: Test Loss: 0.3333, Accuracy: 86.26%, AUC: 0.8632, SENS: 0.8591, SPEC: 0.8674, MCC: 0.7217\n",
      "Current learning rate: 0.000002\n",
      "Epoch 9/20, Train Loss: 0.2878, Train Accuracy: 89.92%\n",
      "Epoch 9/20: Test Loss: 0.3295, Accuracy: 87.10%, AUC: 0.8754, SENS: 0.8468, SPEC: 0.9040, MCC: 0.7431\n",
      "Current learning rate: 0.000000\n",
      "Saved new best model with accuracy: 87.10% and learning rate: 0.000000\n",
      "Epoch 10/20, Train Loss: 0.2871, Train Accuracy: 89.96%\n",
      "Epoch 10/20: Test Loss: 0.3330, Accuracy: 86.84%, AUC: 0.8717, SENS: 0.8501, SPEC: 0.8933, MCC: 0.7364\n",
      "Current learning rate: 0.000000\n",
      "Epoch 11/20, Train Loss: 0.2877, Train Accuracy: 89.96%\n",
      "Epoch 11/20: Test Loss: 0.3319, Accuracy: 86.84%, AUC: 0.8717, SENS: 0.8501, SPEC: 0.8933, MCC: 0.7364\n",
      "Current learning rate: 0.000000\n",
      "Epoch 12/20, Train Loss: 0.2827, Train Accuracy: 90.18%\n",
      "Epoch 12/20: Test Loss: 0.3309, Accuracy: 86.39%, AUC: 0.8651, SENS: 0.8568, SPEC: 0.8735, MCC: 0.7250\n",
      "Current learning rate: 0.000002\n",
      "Epoch 13/20, Train Loss: 0.2828, Train Accuracy: 89.92%\n",
      "Epoch 13/20: Test Loss: 0.3277, Accuracy: 86.65%, AUC: 0.8672, SENS: 0.8624, SPEC: 0.8720, MCC: 0.7296\n",
      "Current learning rate: 0.000004\n",
      "Epoch 14/20, Train Loss: 0.2822, Train Accuracy: 89.96%\n",
      "Epoch 14/20: Test Loss: 0.3286, Accuracy: 86.45%, AUC: 0.8663, SENS: 0.8546, SPEC: 0.8780, MCC: 0.7268\n",
      "Current learning rate: 0.000007\n",
      "Epoch 15/20, Train Loss: 0.2787, Train Accuracy: 90.14%\n",
      "Epoch 15/20: Test Loss: 0.3234, Accuracy: 87.35%, AUC: 0.8764, SENS: 0.8579, SPEC: 0.8948, MCC: 0.7461\n",
      "Current learning rate: 0.000010\n",
      "Saved new best model with accuracy: 87.35% and learning rate: 0.000010\n",
      "Epoch 16/20, Train Loss: 0.2742, Train Accuracy: 89.99%\n",
      "Epoch 16/20: Test Loss: 0.3210, Accuracy: 87.03%, AUC: 0.8722, SENS: 0.8602, SPEC: 0.8841, MCC: 0.7385\n",
      "Current learning rate: 0.000013\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m total_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     65\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_gcn, data_masif \u001b[38;5;129;01min\u001b[39;00m train_combined_loader:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# 处理数据\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     data_gcn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m     input_feat \u001b[38;5;241m=\u001b[39m data_masif[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_feat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/Workspace/xinxinpeng/miniconda3/envs/evescape/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Workspace/xinxinpeng/miniconda3/envs/evescape/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Workspace/xinxinpeng/miniconda3/envs/evescape/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Workspace/xinxinpeng/miniconda3/envs/evescape/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mCombinedDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     12\u001b[0m     graph_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_dataset[idx]\n\u001b[0;32m---> 13\u001b[0m     feature_data, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph_data, feature_data, label\n",
      "File \u001b[0;32m/Workspace/xinxinpeng/miniconda3/envs/evescape/lib/python3.10/site-packages/torch/utils/data/dataset.py:235\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mPeptideDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m current_length \u001b[38;5;241m>\u001b[39m max_vertices:\n\u001b[1;32m     54\u001b[0m         features[key] \u001b[38;5;241m=\u001b[39m features[key][:max_vertices]\n\u001b[0;32m---> 56\u001b[0m     features[key] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan_to_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 所有样本的标签都是\u001b[39;00m\n\u001b[1;32m     59\u001b[0m features_tensor \u001b[38;5;241m=\u001b[39m {key: torch\u001b[38;5;241m.\u001b[39mtensor(val, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnan_to_num\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Workspace/xinxinpeng/miniconda3/envs/evescape/lib/python3.10/site-packages/numpy/lib/type_check.py:498\u001b[0m, in \u001b[0;36mnan_to_num\u001b[0;34m(x, copy, nan, posinf, neginf)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nan_to_num_dispatcher)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnan_to_num\u001b[39m(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, posinf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, neginf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    406\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    Replace NaN with zero and infinity with large finite numbers (default\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    behaviour) or with the numbers defined by the user using the `nan`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    array([222222.+111111.j, 111111.     +0.j, 111111.+222222.j])\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    499\u001b[0m     xtype \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    501\u001b[0m     isscalar \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = AdamW(fusion_model.parameters(), lr=0.00002, weight_decay=6e-1)\n",
    "scheduler_cosine = CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "best_accuracy = 0.0  # 初始化最高准确性\n",
    "best_model1_path = '12_9_ben1transfinger_model2.pth'  # 定义最好模型的保存路径\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for data_gcn, data_masif in data_loader:\n",
    "            # 数据处理\n",
    "            data_gcn.to(device)\n",
    "            input_feat = data_masif['input_feat'].to(device)\n",
    "            rho_coords = data_masif['rho_coords'].to(device)\n",
    "            theta_coords = data_masif['theta_coords'].to(device)\n",
    "            mask = data_masif['mask'].to(device)\n",
    "            labels = data_gcn.y.to(device)\n",
    "            \n",
    "            # 正向传播\n",
    "            outputs = model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # 计算总体指标\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        auc_score = roc_auc_score(all_labels, all_preds)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy, auc_score, sensitivity, specificity, mcc\n",
    "epochs = 20\n",
    "# 训练循环\n",
    "best_accuracy = 0.0  \n",
    "best_lr = 0.0\n",
    "best_weight_decay = 5e-1  # 此值应与你的优化器初始设置相匹配\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    fusion_model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for data_gcn, data_masif in train_combined_loader:\n",
    "        # 处理数据\n",
    "        data_gcn.to(device)\n",
    "        input_feat = data_masif['input_feat'].to(device)\n",
    "        rho_coords = data_masif['rho_coords'].to(device)\n",
    "        theta_coords = data_masif['theta_coords'].to(device)\n",
    "        mask = data_masif['mask'].to(device)\n",
    "        labels = data_gcn.y.to(device)\n",
    "\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = fusion_model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算准确性\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # 输出训练性能\n",
    "    avg_loss = total_loss / len(train_combined_loader)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    test_loss, test_accuracy, test_auc, test_sens, test_spec, test_mcc = evaluate_model(fusion_model, test_combined_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{epochs}: Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, AUC: {test_auc:.4f}, SENS: {test_sens:.4f}, SPEC: {test_spec:.4f}, MCC: {test_mcc:.4f}')\n",
    "    \n",
    "    # 更新调度器\n",
    "    scheduler_cosine.step()\n",
    "    scheduler_plateau.step(test_loss)\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current learning rate: {current_lr:.6f}')\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy  # 更新最高准确性\n",
    "        best_lr = current_lr  # 保存最佳学习率\n",
    "        torch.save(fusion_model.state_dict(), best_model1_path)  # 保存模型\n",
    "        print(f'Saved new best model with accuracy: {best_accuracy:.2f}% and learning rate: {best_lr:.6f}')\n",
    "\n",
    "# 最后输出最佳模型的学习率\n",
    "print(f'Best model learning rate: {best_lr:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# 定义一个加载模型的函数\n",
    "def load_model(model, path='12_9_ben1transfinger_model2.pth'):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f'Model loaded from {path}')\n",
    "    return model\n",
    "\n",
    "# 定义一个绘制 ROC 曲线的函数\n",
    "def plot_roc_curve(labels, scores, title=\"ROC Curve\"):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # 绘制对角线\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# 使用最佳模型在测试集上进行测试并打印所有指标\n",
    "def test_model_and_print_metrics(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_scores = []  # 用于保存正类的概率\n",
    "    all_preds = []   # 保存预测值\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_gcn, data_masif in test_loader:\n",
    "            # 数据处理\n",
    "            data_gcn.to(device)\n",
    "            input_feat = data_masif['input_feat'].to(device)\n",
    "            rho_coords = data_masif['rho_coords'].to(device)\n",
    "            theta_coords = data_masif['theta_coords'].to(device)\n",
    "            mask = data_masif['mask'].to(device)\n",
    "            labels = data_gcn.y.to(device)\n",
    "\n",
    "            # 正向传播\n",
    "            outputs = model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 获取预测概率和预测值\n",
    "            scores = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # 获取正类的预测概率\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()  # 获取预测值\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_scores.extend(scores)  # 保存正类的预测概率\n",
    "            all_preds.extend(preds)    # 保存预测值\n",
    "            total_correct += (preds == labels).sum()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "    # 计算测试集损失\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # 计算 Accuracy\n",
    "    accuracy = total_correct / total_samples * 100\n",
    "\n",
    "    # 计算 AUC\n",
    "    auc_score = roc_auc_score(all_labels, all_scores)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # 计算 Sensitivity 和 Specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # 计算 MCC\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    # 获取当前学习率\n",
    "    #current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # 打印所有指标\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, AUC: {auc_score:.4f}, '\n",
    "          f'SENS: {sensitivity:.4f}, SPEC: {specificity:.4f}, MCC: {mcc:.4f}')\n",
    "    #print(f'Current learning rate: {current_lr:.8f}')\n",
    "    \n",
    "    # 绘制 ROC 曲线\n",
    "    plot_roc_curve(all_labels, all_scores, title=\"ROC Curve on Test Set\")\n",
    "best_model2_path = '12_9_ben1transfinger_model2.pth' \n",
    "# 加载模型并进行测试\n",
    "fusion_model = FusionModel(model_gcn, model_masif, 40840, num_classes=2).to(device)\n",
    "fusion_model.to(device)\n",
    "# 加载之前保存的最佳模型\n",
    "fusion_model = load_model(fusion_model, best_model2_path)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 使用最佳模型在测试集上进行推理并绘制 ROC 曲线\n",
    "test_model_and_print_metrics(fusion_model, test_combined_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import MultiheadAttention\n",
    "\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, model_gcn, model_masif, output_features, num_classes):\n",
    "        super(FusionModel, self).__init__()\n",
    "        self.model_gcn = model_gcn\n",
    "        self.model_masif = model_masif\n",
    "        self.expand_gcn = nn.Linear(16, 256)  # 升维GCN特征至256\n",
    "        self.reduce_masif = nn.Linear(40840, 256)  # 降维MaSIF特征至256\n",
    "        \n",
    "        # 添加 MultiheadAttention 层\n",
    "        self.attention = MultiheadAttention(embed_dim=512, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # 用于预处理注意力层输出的线性层\n",
    "        self.attn_linearity = nn.Linear(512, 256)\n",
    "        \n",
    "        # 融合后的特征进一步连接到分类器\n",
    "        self.fusion_layer = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, data_gcn, data_masif):\n",
    "        gcn_features = self.model_gcn(data_gcn, return_features=True)\n",
    "        masif_features = self.model_masif(data_masif['input_feat'], data_masif['rho_coords'], data_masif['theta_coords'], data_masif['mask'], return_features=True)\n",
    "        \n",
    "        gcn_features = F.relu(self.expand_gcn(gcn_features))\n",
    "        masif_features = F.relu(self.reduce_masif(masif_features))\n",
    "\n",
    "        # 将 GCN 和 MaSIF 特征进行拼接后送入注意力层\n",
    "        combined_features = torch.cat((gcn_features, masif_features), dim=1).unsqueeze(0)  # 注意调整形状以匹配MultiheadAttention的输入要求\n",
    "        \n",
    "        # 应用 Multihead Attention\n",
    "        attn_output, attn_weights = self.attention(combined_features, combined_features, combined_features)\n",
    "        attn_output = attn_output.squeeze(0)  # 移除多余的批量维度\n",
    "        \n",
    "        # 可选：使用额外的线性层处理注意力层输出\n",
    "        attn_output = self.attn_linearity(attn_output)\n",
    "        \n",
    "        # 分类层\n",
    "        output = self.fusion_layer(attn_output)\n",
    "        return F.log_softmax(output, dim=1)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 实例化单独的模型\n",
    "model_gcn = ImprovedGCNWithTransformer(num_features=3604, num_classes=2).to(device)\n",
    "model_masif = MaSIF_site_PyTorch(n_thetas=16, n_rhos=5, n_feat=5, n_rotations=8).to(device)\n",
    "\n",
    "# 假设从GCN和MaSIF模型中提取的特征数量，需要根据具体情况来设置\n",
    "gcn_output_features = 32  # 假设GCN模型最后一个GAT层输出32维特征\n",
    "masif_output_features = 5 * 8  # MaSIF模型输出8次旋转的5维特征\n",
    "total_output_features = 40840\n",
    "\n",
    "# 实例化融合模型\n",
    "fusion_model = FusionModel(model_gcn, model_masif, 40840, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = AdamW(fusion_model.parameters(), lr=0.00002, weight_decay=6e-1)\n",
    "scheduler_cosine = CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "best_accuracy = 0.0  # 初始化最高准确性\n",
    "best_model_path = '12_9_ben1transfinger_model3.pth'  # 定义最好模型的保存路径\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for data_gcn, data_masif in data_loader:\n",
    "            # 数据处理\n",
    "            data_gcn.to(device)\n",
    "            input_feat = data_masif['input_feat'].to(device)\n",
    "            rho_coords = data_masif['rho_coords'].to(device)\n",
    "            theta_coords = data_masif['theta_coords'].to(device)\n",
    "            mask = data_masif['mask'].to(device)\n",
    "            labels = data_gcn.y.to(device)\n",
    "            \n",
    "            # 正向传播\n",
    "            outputs = model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # 计算总体指标\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        auc_score = roc_auc_score(all_labels, all_preds)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy, auc_score, sensitivity, specificity, mcc\n",
    "epochs = 30\n",
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    fusion_model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for data_gcn, data_masif in train_combined_loader:\n",
    "        # 处理数据\n",
    "        data_gcn.to(device)\n",
    "        input_feat = data_masif['input_feat'].to(device)\n",
    "        rho_coords = data_masif['rho_coords'].to(device)\n",
    "        theta_coords = data_masif['theta_coords'].to(device)\n",
    "        mask = data_masif['mask'].to(device)\n",
    "        labels = data_gcn.y.to(device)\n",
    "\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 正向传播\n",
    "        outputs = fusion_model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算准确性\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # 输出训练性能\n",
    "    avg_loss = total_loss / len(train_combined_loader)\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    test_loss, test_accuracy, test_auc, test_sens, test_spec, test_mcc = evaluate_model(fusion_model, test_combined_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{epochs}: Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, AUC: {test_auc:.4f}, SENS: {test_sens:.4f}, SPEC: {test_spec:.4f}, MCC: {test_mcc:.4f}')\n",
    "    # 检查是否为最好的模型\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy  # 更新最高准确性\n",
    "        torch.save(fusion_model.state_dict(), best_model_path)  # 保存模型\n",
    "        print(f'Saved new best model with accuracy: {best_accuracy:.2f}%')\n",
    "    scheduler_cosine.step()\n",
    "    scheduler_plateau.step(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# 定义一个加载模型的函数\n",
    "def load_model(model, path='12_9_ben1transfinger_model3.pth'):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f'Model loaded from {path}')\n",
    "    return model\n",
    "\n",
    "# 定义一个绘制 ROC 曲线的函数\n",
    "def plot_roc_curve(labels, scores, title=\"ROC Curve\"):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # 绘制对角线\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# 使用最佳模型在测试集上进行测试并打印所有指标\n",
    "def test_model_and_print_metrics(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_scores = []  # 用于保存正类的概率\n",
    "    all_preds = []   # 保存预测值\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_gcn, data_masif in test_loader:\n",
    "            # 数据处理\n",
    "            data_gcn.to(device)\n",
    "            input_feat = data_masif['input_feat'].to(device)\n",
    "            rho_coords = data_masif['rho_coords'].to(device)\n",
    "            theta_coords = data_masif['theta_coords'].to(device)\n",
    "            mask = data_masif['mask'].to(device)\n",
    "            labels = data_gcn.y.to(device)\n",
    "\n",
    "            # 正向传播\n",
    "            outputs = model(data_gcn, {'input_feat': input_feat, 'rho_coords': rho_coords, 'theta_coords': theta_coords, 'mask': mask})\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 获取预测概率和预测值\n",
    "            scores = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # 获取正类的预测概率\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()  # 获取预测值\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_scores.extend(scores)  # 保存正类的预测概率\n",
    "            all_preds.extend(preds)    # 保存预测值\n",
    "            total_correct += (preds == labels).sum()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "    # 计算测试集损失\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # 计算 Accuracy\n",
    "    accuracy = total_correct / total_samples * 100\n",
    "\n",
    "    # 计算 AUC\n",
    "    auc_score = roc_auc_score(all_labels, all_scores)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # 计算 Sensitivity 和 Specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # 计算 MCC\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "    # 获取当前学习率\n",
    "    #current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # 打印所有指标\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, AUC: {auc_score:.4f}, '\n",
    "          f'SENS: {sensitivity:.4f}, SPEC: {specificity:.4f}, MCC: {mcc:.4f}')\n",
    "    #print(f'Current learning rate: {current_lr:.8f}')\n",
    "    \n",
    "    # 绘制 ROC 曲线\n",
    "    plot_roc_curve(all_labels, all_scores, title=\"ROC Curve on Test Set\")\n",
    "best_model2_path = '12_9_ben1transfinger_model1.pth' \n",
    "# 加载模型并进行测试\n",
    "fusion_model = FusionModel(model_gcn, model_masif, 40840, num_classes=2).to(device)\n",
    "fusion_model.to(device)\n",
    "# 加载之前保存的最佳模型\n",
    "fusion_model = load_model(fusion_model, best_model2_path)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 使用最佳模型在测试集上进行推理并绘制 ROC 曲线\n",
    "test_model_and_print_metrics(fusion_model, test_combined_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
